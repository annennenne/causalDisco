% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bnlearn_search.R
\name{BnlearnSearch}
\alias{BnlearnSearch}
\title{R6 Interface to bnlearn Search Algorithms}
\value{
An R6 object with the methods documented below.
}
\description{
A wrapper that lets you drive \code{bnlearns}’s structure-learning
algorithms within the \code{causalDisco} framework.
}
\examples{
### bnlearn_search R6 class examples ###

# Generally, we do not recommend using the R6 classes directly, but rather
# use the disco() or any method function, for example pc(), instead.

# Load data
data("tpc_example")

# Recommended:
my_pc <- pc(engine = "bnlearn", test = "fisher_z", alpha = 0.05)
result <- my_pc(tpc_example)

# or
result <- disco(data = tpc_example, method = my_pc)

plot(result)

# Using R6 class:
s <- BnlearnSearch$new()

s$set_data(tpc_example)
s$set_test(method = "fisher_z", alpha = 0.05)
s$set_alg("pc")

g <- s$run_search()

plot(g)
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{data}}{A \code{data.frame} holding the data set currently attached to the
search object. Can be set with \code{set_data()}.}

\item{\code{score}}{Character scalar naming the score function used in
bnlearn. Can be set with \code{$set_score()}.
Recognised values are:

\strong{Discrete – categorical}
\itemize{
\item \code{"loglik"} — log-likelihood
\item \code{"aic"} — Akaike Information Criterion
\item \code{"bic"} — Bayesian Information Criterion
\item \code{"ebic"} — Extended BIC
\item \code{"pred-loglik"} — predictive log-likelihood
\item \code{"bde"} — Bayesian Dirichlet equivalent (uniform)
\item \code{"bds"} — Bayesian Dirichlet score
\item \code{"mbde"} — modified BDE
\item \code{"bdla"} — locally averaged BDE
\item \code{"k2"} — K2 score
\item \code{"fnml"} — factorised NML
\item \code{"qnml"} — quotient NML
\item \code{"nal"} — node-average log-likelihood
\item \code{"pnal"} — penalised node-average log-likelihood
}
\strong{Gaussian}
\itemize{
\item \code{"loglik-g"}, \code{"aic-g"}, \code{"bic-g"},
\code{"ebic-g"}, \code{"pred-loglik-g"}
\item \code{"bge"} — Gaussian posterior density
\item \code{"nal-g"} — node-average log-likelihood
\item \code{"pnal-g"} — penalised node-average log-likelihood
}
\strong{Conditional Gaussian}
\itemize{
\item \code{"loglik-cg"}, \code{"aic-cg"}, \code{"bic-cg"},
\code{"ebic-cg"}, \code{"pred-loglik-cg"},
\code{"nal-cg"}, \code{"pnal-cg"}
}}

\item{\code{test}}{Character scalar naming the conditional-independence test
passed to bnlearn. Can be set with \code{$set_score()}.
Recognised values are:

\strong{Discrete – categorical}
\itemize{
\item \code{"mi"} – mutual information
\item \code{"mi-adf"} – mutual information with adjusted d.f.
\item \code{"mc-mi"} – Monte Carlo mutual information
\item \code{"smc-mi"} – sequential Monte Carlo mutual information
\item \code{"sp-mi"} – semi-parametric mutual information
\item \code{"mi-sh"} – mutual information (shrinkage)
\item \code{"x2"} – chi-squared
\item \code{"x2-adf"} – chi-squared with adjusted d.f.
\item \code{"mc-x2"} – Monte Carlo chi-squared
\item \code{"smc-x2"} – sequential Monte Carlo chi-squared
\item \code{"sp-x2"} – semi-parametric chi-squared
}

\strong{Discrete – ordered factors}
\itemize{
\item \code{"jt"} – Jonckheere–Terpstra
\item \code{"mc-jt"} – Monte Carlo Jonckheere–Terpstra
\item \code{"smc-jt"} – sequential Monte Carlo Jonckheere–Terpstra
}

\strong{Gaussian}
\itemize{
\item \code{"cor"} – Pearson correlation
\item \code{"mc-cor"} – Monte Carlo Pearson correlation
\item \code{"smc-cor"} – sequential Monte Carlo Pearson correlation
\item \code{"zf"} / \code{"fisher_z"} – Fisher Z test
\item \code{"mc-zf"} – Monte Carlo Fisher Z
\item \code{"smc-zf"} – sequential Monte Carlo Fisher Z
\item \code{"mi-g"} – mutual information (Gaussian)
\item \code{"mc-mi-g"} – Monte Carlo mutual information (Gaussian)
\item \code{"smc-mi-g"} – sequential Monte Carlo mutual information (Gaussian)
\item \code{"mi-g-sh"} – mutual information (Gaussian, shrinkage)
}

\strong{Conditional Gaussian}
\itemize{
\item \code{"mi-cg"} – mutual information (conditional Gaussian)
}}

\item{\code{alg}}{Function generated by \code{$set_alg()} that runs a
structure-learning algorithm from bnlearn. Recognised values are:

\strong{Constraint-based}
\itemize{
\item \code{"pc"} – PC-stable algorithm
\item \code{"gs"} – Grow-Shrink
\item \code{"iamb"} – Incremental Association Markov Blanket
\item \code{"fast.iamb"} – Fast-IAMB
\item \code{"inter.iamb"} – Interleaved-IAMB
\item \code{"iamb.fdr"} – IAMB with FDR control
}

\strong{Local / skeleton discovery}
\itemize{
\item \code{"mmpc"} – Max–Min Parents and Children
\item \code{"si.hiton.pc"} – Semi-Interleaved HITON-PC
\item \code{"hpc"} – Hybrid Parents and Children
}

\strong{Score-based}
\itemize{
\item \code{"hc"} – Hill-Climbing
\item \code{"tabu"} – Tabu search
}

\strong{Hybrid}
\itemize{
\item \code{"mmhc"} – Max–Min Hill-Climbing
\item \code{"rsmax2"} – Restricted Maximisation (two-stage)
\item \code{"h2pc"} – Hybrid HPC–PC
}

\strong{Pairwise mutual-information learners}
\itemize{
\item \code{"chow.liu"} – Chow–Liu tree
\item \code{"aracne"} – ARACNE network
}}

\item{\code{params}}{A list of extra tuning parameters stored by \code{set_params()}
and spliced into the learner call.}

\item{\code{knowledge}}{A list with elements \code{whitelist} and \code{blacklist}
containing prior-knowledge constraints added via \code{set_knowledge()}.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-BnlearnSearch-new}{\code{BnlearnSearch$new()}}
\item \href{#method-BnlearnSearch-set_params}{\code{BnlearnSearch$set_params()}}
\item \href{#method-BnlearnSearch-set_data}{\code{BnlearnSearch$set_data()}}
\item \href{#method-BnlearnSearch-set_test}{\code{BnlearnSearch$set_test()}}
\item \href{#method-BnlearnSearch-set_score}{\code{BnlearnSearch$set_score()}}
\item \href{#method-BnlearnSearch-set_alg}{\code{BnlearnSearch$set_alg()}}
\item \href{#method-BnlearnSearch-set_knowledge}{\code{BnlearnSearch$set_knowledge()}}
\item \href{#method-BnlearnSearch-run_search}{\code{BnlearnSearch$run_search()}}
\item \href{#method-BnlearnSearch-clone}{\code{BnlearnSearch$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BnlearnSearch-new"></a>}}
\if{latex}{\out{\hypertarget{method-BnlearnSearch-new}{}}}
\subsection{Method \code{new()}}{
Constructor for the \code{BnlearnSearch} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BnlearnSearch$new()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BnlearnSearch-set_params"></a>}}
\if{latex}{\out{\hypertarget{method-BnlearnSearch-set_params}{}}}
\subsection{Method \code{set_params()}}{
Set the parameters for the search algorithm.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BnlearnSearch$set_params(params)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{params}}{A parameter to set.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BnlearnSearch-set_data"></a>}}
\if{latex}{\out{\hypertarget{method-BnlearnSearch-set_data}{}}}
\subsection{Method \code{set_data()}}{
Set the data for the search algorithm.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BnlearnSearch$set_data(data)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{data}}{A data frame containing the data to use for the search.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BnlearnSearch-set_test"></a>}}
\if{latex}{\out{\hypertarget{method-BnlearnSearch-set_test}{}}}
\subsection{Method \code{set_test()}}{
Set the conditional-independence test to use in the search algorithm.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BnlearnSearch$set_test(method, alpha = 0.05)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{method}}{Character naming the test to use.}

\item{\code{alpha}}{Significance level for the test.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BnlearnSearch-set_score"></a>}}
\if{latex}{\out{\hypertarget{method-BnlearnSearch-set_score}{}}}
\subsection{Method \code{set_score()}}{
Set the score function for the search algorithm.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BnlearnSearch$set_score(method)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{method}}{Character naming the score function to use.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BnlearnSearch-set_alg"></a>}}
\if{latex}{\out{\hypertarget{method-BnlearnSearch-set_alg}{}}}
\subsection{Method \code{set_alg()}}{
Set the causal discovery algorithm to use.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BnlearnSearch$set_alg(method, args = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{method}}{Character naming the algorithm to use.}

\item{\code{args}}{A list of additional arguments to pass to the algorithm.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BnlearnSearch-set_knowledge"></a>}}
\if{latex}{\out{\hypertarget{method-BnlearnSearch-set_knowledge}{}}}
\subsection{Method \code{set_knowledge()}}{
Set the prior knowledge for the search algorithm using a knowledge object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BnlearnSearch$set_knowledge(knowledge_obj)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{knowledge_obj}}{A knowledge object containing prior knowledge.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BnlearnSearch-run_search"></a>}}
\if{latex}{\out{\hypertarget{method-BnlearnSearch-run_search}{}}}
\subsection{Method \code{run_search()}}{
Run the search algorithm on the currently set data.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BnlearnSearch$run_search(data = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{data}}{A data frame containing the data to use for the search.
If NULL, the currently set data will be used, i.e. \code{self$data}.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BnlearnSearch-clone"></a>}}
\if{latex}{\out{\hypertarget{method-BnlearnSearch-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BnlearnSearch$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
